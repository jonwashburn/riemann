import Mathlib.Algebra.Lie.OfAssociative
import Mathlib.Analysis.CStarAlgebra.Classes
import Mathlib.Analysis.Calculus.Gradient.Basic
import Mathlib.Analysis.InnerProductSpace.Calculus
import Mathlib.Analysis.InnerProductSpace.Harmonic.Constructions
import Mathlib.Data.Real.CompleteField
import Mathlib.LinearAlgebra.Complex.FiniteDimensional
import Mathlib.Order.CompletePartialOrder
import Riemann.RS.PoissonKernelAnalysis
import Mathlib.Analysis.InnerProductSpace.PiL2
import Mathlib.Analysis.InnerProductSpace.Basic
import Mathlib.Analysis.InnerProductSpace.ProdL2
/-

# Laplacian and harmonic functions on finiteâ€‘dimensional real inner product spaces

We define:

* `hessian â„ f x` : the second FrÃ©chet derivative (Hessian) of a scalar field
  `f : E â†’ â„` at a point `x : E`, as a continuous bilinear map `E â†’L[â„] E â†’L[â„] â„`.

* `laplacian â„ f x` : the Laplacian of `f` at `x`, defined as the trace of the Hessian
  in an orthonormal basis of the finiteâ€‘dimensional real inner product space `E`.

* `IsHarmonicOn f s` : a scalar field `f : E â†’ â„` is harmonic on a set `s` if it is
  twice continuously differentiable at every point of `s` and its Laplacian vanishes there.

The Laplacian is defined for any finiteâ€‘dimensional real inner product space `E`; it is
canonically independent of the choice of orthonormal basis (this is proved via standard
linear algebra but not used in the basic API).

Future extensions include:
* explicit coordinate formulas on `â„^n` and `â„ Ã— â„`,
* invariance under linear (and affine) isometries,
* connections with divergence and the Hessian of vector fields,
* the classical result that the real and imaginary parts of analytic functions are harmonic.
-/

noncomputable section

open scoped BigOperators

namespace Analysis

/-! ## Hessian -/

section Hessian

variable {E : Type*} [NormedAddCommGroup E] [NormedSpace â„ E]

/-- The Hessian of a scalar field `f : E â†’ â„` at `x : E`, defined as the second FrÃ©chet
derivative `fderiv â„ (fun y => fderiv â„ f y) x`.

We work over `â„` because the Laplacian is a realâ€‘analytic notion. -/
def hessian (f : E â†’ â„) (x : E) : E â†’L[â„] E â†’L[â„] â„ :=
  fderiv â„ (fun y => fderiv â„ f y) x

/-- A convenience lemma: the Hessian is the FrÃ©chet derivative of `fderiv â„ f`. -/
lemma hessian_def (f : E â†’ â„) (x : E) :
    hessian f x = fderiv â„ (fun y => fderiv â„ f y) x := rfl

/-- If `f` is constant, then its Hessian vanishes everywhere. -/
lemma hessian_const (c : â„) (x : E) :
    hessian (fun _ : E => c) x = 0 := by
  -- First derivative is identically zero, hence so is its derivative.
  ext v w
  simp [hessian]  -- both levels of derivatives are zero

/-- If `f` is affineâ€‘linear, then its Hessian is zero.

More precisely, for any continuous linear map `L : E â†’L[â„] â„` and constant `c`, the
Hessian of `x â†¦ L x + c` vanishes. -/
lemma hessian_linear_add_const (L : E â†’L[â„] â„) (c : â„) (x : E) :
    hessian (fun y : E => L y + c) x = 0 := by
  -- `fderiv` of an affine map is constant `L`, so the second derivative is zero.
  ext v w
  have hâ‚ : fderiv â„ (fun y : E => L y + c) = fun _ => L := by
    -- derivative is constant in `y`
    funext y
    -- `fderiv` of `y â†¦ L y + c` is the same as the derivative of `y â†¦ L y`
    -- (the constant term disappears), and this derivative is `L`.
    have hAdd :
        fderiv â„ (fun y : E => L y + c) y =
          fderiv â„ (fun y : E => L y) y := by
      rw [fderiv_add_const]
    have hL : fderiv â„ (fun y : E => L y) y = L := by
      exact L.fderiv
    simp [hAdd, hL]
  -- Now differentiate once more: the derivative of the constant map `fun _ => L` is zero.
  simp [hessian]  -- both derivatives vanish

/-!
If desired, one can use the symmetry results from `FDeriv/Symmetric.lean` to prove that
`hessian f x` is symmetric under suitable hypotheses (`C^2` regularity). We do not need this
yet for the basic Laplacian / harmonic API, so we leave those lemmas for a later development.
-/

end Hessian

/-! ## Laplacian -/

section Laplacian

variable {E : Type*} [NormedAddCommGroup E] [InnerProductSpace â„ E]

lemma iteratedFDeriv_two_eq_hessian (f : E â†’ â„) (x : E) (m : Fin 2 â†’ E) :
    iteratedFDeriv â„ 2 f x m = hessian f x (m 0) (m 1) := by
  simpa [hessian] using (iteratedFDeriv_two_apply (ð•œ := â„) (f := f) (z := x) m)

variable [FiniteDimensional â„ E]

/-- Scalar Laplacian on a finite-dimensional real inner product space, re-exported from mathlib. -/
abbrev laplacian (f : E â†’ â„) (x : E) : â„ :=
  InnerProductSpace.laplacian (E := E) (F := â„) f x

lemma laplacian_eq_sum_orthonormal
  {Î¹ : Type*} [Fintype Î¹] (b : OrthonormalBasis Î¹ â„ E) (f : E â†’ â„) (x : E) :
    laplacian f x = âˆ‘ i, hessian f x (b i) (b i) := by
  classical
  have h :=
    congrArg (fun g : E â†’ â„ => g x)
      (InnerProductSpace.laplacian_eq_iteratedFDeriv_orthonormalBasis
        (E := E) (F := â„) (f := f) (v := b))
  simpa [laplacian, iteratedFDeriv_two_eq_hessian] using h

lemma laplacian_def (f : E â†’ â„) (x : E) :
    laplacian f x =
      âˆ‘ i, hessian f x ((stdOrthonormalBasis â„ E) i)
        ((stdOrthonormalBasis â„ E) i) :=
  laplacian_eq_sum_orthonormal (b := stdOrthonormalBasis â„ E) f x

/-!
### Specializations and coordinate bridges

In many applications we work on concrete Hilbert spaces such as the `LÂ²` product
`WithLp 2 (â„ Ã— â„)`.  The following helper lemma simply specializes the general
Laplacian definition to this setting; more refined coordinate identifications
are built on top of it in `DiagonalBounds.lean`.
-/

lemma laplacian_withLp_prod
    (f : WithLp 2 (â„ Ã— â„) â†’ â„) (x : WithLp 2 (â„ Ã— â„)) :
    laplacian f x =
      âˆ‘ i, hessian f x
        ((stdOrthonormalBasis â„ (WithLp 2 (â„ Ã— â„))) i)
        ((stdOrthonormalBasis â„ (WithLp 2 (â„ Ã— â„))) i) :=
  laplacian_def (E := WithLp 2 (â„ Ã— â„)) f x

/-!
### Bridge to coordinate derivatives
-/

/-- The Laplacian on `WithLp 2 (â„ Ã— â„)` expands to the sum of second derivatives along
    the coordinate axes `(1,0)` and `(0,1)`. -/
lemma laplacian_withLp_prod_coords
    (f : WithLp 2 (â„ Ã— â„) â†’ â„) (x : WithLp 2 (â„ Ã— â„)) :
    laplacian f x =
      hessian f x (1, 0) (1, 0) + hessian f x (0, 1) (0, 1) := by
  let bR := OrthonormalBasis.singleton (Fin 1) â„
  let B := bR.prod bR
  rw [laplacian_eq_sum_orthonormal B]
  rw [Fintype.sum_sum_type]
  simp only [Finset.univ_unique, Fin.default_eq_zero, Finset.sum_singleton]
  have h1 : B (Sum.inl 0) = (1, 0) := by
    rw [OrthonormalBasis.prod_apply, Sum.elim_inl]
    simp [bR]
  have h2 : B (Sum.inr 0) = (0, 1) := by
    rw [OrthonormalBasis.prod_apply, Sum.elim_inr]
    simp [bR]
  rw [h1, h2]

/-- Derivative of `x â†¦ f(x, y)` matches `fderiv f (x, y) (1, 0)`. -/
lemma deriv_slice_fst_eq_fderiv {F : Type*} [NormedAddCommGroup F] [NormedSpace â„ F]
    {f : WithLp 2 (â„ Ã— â„) â†’ F} {p : WithLp 2 (â„ Ã— â„)}
    (h : DifferentiableAt â„ f p) :
    deriv (fun x => f (x, p.2)) p.1 = fderiv â„ f p (1, 0) := by
  let v : WithLp 2 (â„ Ã— â„) := (1, 0)
  let c : WithLp 2 (â„ Ã— â„) := (0, p.2)
  have h_curve : HasDerivAt (fun x : â„ => x â€¢ v + c) v p.1 := by
    apply HasDerivAt.add_const
    convert HasDerivAt.smul_const (hasDerivAt_id p.1) v using 1
    simp
  have h_eq : (fun x => x â€¢ v + c) = (fun x => (x, p.2)) := by
    funext x
    change (x â€¢ (1 : â„), x â€¢ (0 : â„)) + (0, p.2) = (x, p.2)
    simp
  rw [h_eq] at h_curve
  exact (h.hasFDerivAt.comp_hasDerivAt p.1 h_curve).deriv

/-- Derivative of `y â†¦ f(x, y)` matches `fderiv f (x, y) (0, 1)`. -/
lemma deriv_slice_snd_eq_fderiv {F : Type*} [NormedAddCommGroup F] [NormedSpace â„ F]
    {f : WithLp 2 (â„ Ã— â„) â†’ F} {p : WithLp 2 (â„ Ã— â„)}
    (h : DifferentiableAt â„ f p) :
    deriv (fun y => f (p.1, y)) p.2 = fderiv â„ f p (0, 1) := by
  let v : WithLp 2 (â„ Ã— â„) := (0, 1)
  let c : WithLp 2 (â„ Ã— â„) := (p.1, 0)
  have h_curve : HasDerivAt (fun y : â„ => y â€¢ v + c) v p.2 := by
    apply HasDerivAt.add_const
    convert HasDerivAt.smul_const (hasDerivAt_id p.2) v using 1
    simp
  have h_eq : (fun y => y â€¢ v + c) = (fun y => (p.1, y)) := by
    funext y
    change (y â€¢ (0 : â„), y â€¢ (1 : â„)) + (p.1, 0) = (p.1, y)
    simp
  rw [h_eq] at h_curve
  exact (h.hasFDerivAt.comp_hasDerivAt p.2 h_curve).deriv

/-- The Hessian entry `hessian f q (1,0) (1,0)` corresponds to the iterated x-derivative.

We assume in addition that the FrÃ©chet derivative `p â†¦ fderiv â„ f p` is differentiable at `q`,
which is the natural `C^2` regularity condition. -/
lemma hessian_fst_fst_slice
    (f : WithLp 2 (â„ Ã— â„) â†’ â„) (q : WithLp 2 (â„ Ã— â„))
    (h : ContDiff â„ 2 f)
    (h_fderiv_diff : DifferentiableAt â„ (fun p : WithLp 2 (â„ Ã— â„) => fderiv â„ f p) q) :
    hessian f q (1, 0) (1, 0) =
      deriv (fun x => deriv (fun x' => f (x', q.2)) x) q.1 := by
  classical
  let v : WithLp 2 (â„ Ã— â„) := (1, 0)
  -- By definition, the Hessian is the FrÃ©chet derivative of the FrÃ©chet derivative.
  have hdef :
      hessian f q v v =
        (fderiv â„ (fun p : WithLp 2 (â„ Ã— â„) => fderiv â„ f p) q v) v := rfl
  -- Define `g(p) = fderiv f p v` (directional derivative along `v`).
  let g : WithLp 2 (â„ Ã— â„) â†’ â„ := fun p => fderiv â„ f p v
  -- From differentiability of `p â†¦ fderiv f p` at `q`, evaluation at `v` is differentiable.
  have h_g_diff : DifferentiableAt â„ g q :=
    h_fderiv_diff.clm_apply (differentiableAt_const v)

  -- First, identify the Hessian entry as the x-slice derivative of `g`.
  have hg_slice :
      hessian f q v v =
      deriv (fun x => g (x, q.2)) q.1 := by
    -- Apply the slice lemma to the CLM-valued map `p â†¦ fderiv f p`.
    have h_clm :
        deriv (fun x => fderiv â„ f (x, q.2)) q.1 =
          fderiv â„ (fun p : WithLp 2 (â„ Ã— â„) => fderiv â„ f p) q v := by
      -- `deriv_slice_fst_eq_fderiv` specialized to CLM-valued functions
      have := deriv_slice_fst_eq_fderiv
        (F := WithLp 2 (â„ Ã— â„) â†’L[â„] â„)
        (f := fun p : WithLp 2 (â„ Ã— â„) => fderiv â„ f p)
        (p := q) h_fderiv_diff
      simpa [v] using this

    -- By `hdef`, the Hessian is `((fderiv â€¦ q) v) v`.
    -- By `h_clm`, `(fderiv â€¦ q) v` is the derivative of the slice.
    -- So applying `v` to both sides gives:
    have hâ‚ :
        hessian f q v v =
          (deriv (fun x => fderiv â„ f (x, q.2)) q.1) v := by
      have := congrArg (fun L => L v) h_clm
      simpa [hdef] using this.symm

    -- Now commute evaluation at `v` past `deriv` using the CLM chain rule.
    have h_comm :
        (deriv (fun x => fderiv â„ f (x, q.2)) q.1) v =
        deriv (fun x => fderiv â„ f (x, q.2) v) q.1 := by
      classical
      -- View `x â†¦ fderiv f (x, q.2) v` as the composition of
      -- `c x := fderiv f (x, q.2)` with the constant vector `u x := v`,
      -- and apply the chain rule for evaluation of continuous linear maps.
      let c : â„ â†’ WithLp 2 (â„ Ã— â„) â†’L[â„] â„ :=
        fun x => fderiv â„ f (x, q.2)
      let u : â„ â†’ WithLp 2 (â„ Ã— â„) := fun _ => v
      -- differentiability of `c` comes from `h_fderiv_diff` and the slice `x â†¦ (x, q.2)`
      have h_slice :
          DifferentiableAt â„
            (fun x : â„ => ((x, q.2) : WithLp 2 (â„ Ã— â„))) q.1 := by
        have hx : DifferentiableAt â„ (fun x : â„ => x) q.1 := differentiableAt_id
        have hy : DifferentiableAt â„ (fun _ : â„ => q.2) q.1 := differentiableAt_const _
        simp
      have hc : DifferentiableAt â„ c q.1 :=
        h_fderiv_diff.comp q.1 h_slice
      have hu : DifferentiableAt â„ u q.1 := differentiableAt_const _
      -- Apply CLM chain rule to `x â†¦ c x (u x)`.
      have h' := deriv_clm_apply (ð•œ := â„) (c := c) (u := u) hc hu
      -- Since `u` is constant, its derivative vanishes and we obtain the desired commutation.
      have h'' :
          deriv (fun x => c x (u x)) q.1 =
            deriv c q.1 (u q.1) := by
        simpa [u, deriv_const, add_comm] using h'
      -- Rewrite in terms of the original functions.
      simpa [c, u] using h''.symm

    -- Combine `hâ‚` and `h_comm` and unfold `g` to finish.
    have := hâ‚.trans h_comm
    simpa [g] using this

  -- Now identify `g (x, q.2)` with the scalar derivative in the `x`-direction.
  have h_eq_fun :
      (fun x => g (x, q.2)) =
        fun x => deriv (fun x' => f (x', q.2)) x := by
    funext x
    change fderiv â„ f (x, q.2) v =
      deriv (fun x' => f (x', q.2)) x
    have h_f_diff : DifferentiableAt â„ f (x, q.2) :=
      h.differentiable (by norm_num) _
    have hx :=
      (deriv_slice_fst_eq_fderiv (F := â„) (f := f) (p := (x, q.2)) h_f_diff)
    -- `hx` says `deriv (fun x' => f (x', q.2)) x = fderiv â„ f (x, q.2) (1, 0)`.
    -- Rewrite to match our goal.
    simpa [v] using hx.symm

  -- Therefore the outer derivatives agree at `q.1`.
  have h_eq_deriv :
      deriv (fun x => g (x, q.2)) q.1 =
        deriv (fun x => deriv (fun x' => f (x', q.2)) x) q.1 := by
    simp [h_eq_fun]

  -- Finally combine `hg_slice` with `h_eq_deriv` and unfold `v`.
  have := hg_slice.trans h_eq_deriv
  simpa [v] using this

/-- The Hessian entry `hessian f q (0,1) (0,1)` corresponds to the iterated y-derivative. -/
lemma hessian_snd_snd_slice
    (f : WithLp 2 (â„ Ã— â„) â†’ â„) (q : WithLp 2 (â„ Ã— â„))
    (h : ContDiff â„ 2 f) :
    hessian f q (0, 1) (0, 1) = deriv (fun y => deriv (fun y' => f (q.1, y')) y) q.2 := by
  let v : WithLp 2 (â„ Ã— â„) := (0, 1)
  rw [hessian_def]
  let g := fderiv â„ f
  -- From `C^2` regularity of `f`, the map `p â†¦ fderiv f p` is `C^1`, hence differentiable.
  have h_g_diff : DifferentiableAt â„ g q := by
    -- Apply `contDiff_succ_iff_fderiv` with `n = 1`.
    have h' : ContDiff â„ (1 + 1) f := by
      simpa using h
    have h2 := (contDiff_succ_iff_fderiv (ð•œ := â„) (f := f) (n := 1)).1 h'
    -- Extract `ContDiff â„ 1 (fderiv â„ f)` from the conjunction.
    have h_fderiv_CD : ContDiff â„ 1 (fderiv â„ f) := h2.2.2
    -- Specialize at the point `q`.
    exact (h_fderiv_CD.differentiable (by norm_num) q)
  have step1 := deriv_slice_snd_eq_fderiv (F := WithLp 2 (â„ Ã— â„) â†’L[â„] â„) h_g_diff
  rw [â† step1]
  have h_comm : deriv (fun y => g (q.1, y)) q.2 v =
                deriv (fun y => g (q.1, y) v) q.2 := by
    classical
    -- As in the `x`â€‘direction case, commute evaluation at `v` past `deriv`
    -- using the chain rule for CLM evaluation.
    let c : â„ â†’ WithLp 2 (â„ Ã— â„) â†’L[â„] â„ :=
      fun y => g (q.1, y)
    let u : â„ â†’ WithLp 2 (â„ Ã— â„) := fun _ => v
    -- The slice `y â†¦ (q.1, y)` is differentiable.
    have h_slice :
        DifferentiableAt â„
          (fun y : â„ => ((q.1, y) : WithLp 2 (â„ Ã— â„))) q.2 := by
      have hx : DifferentiableAt â„ (fun _ : â„ => q.1) q.2 := differentiableAt_const _
      have hy : DifferentiableAt â„ (fun y : â„ => y) q.2 := differentiableAt_id
      have hxy : DifferentiableAt â„ (fun y : â„ => (q.1, y)) q.2 :=
        (DifferentiableAt.prodMk hx hy)
      simpa using hxy
    -- Differentiability of `c` at `q.2` comes from that of `g` at `q`.
    have hc : DifferentiableAt â„ c q.2 :=
      h_g_diff.comp q.2 h_slice
    have hu : DifferentiableAt â„ u q.2 := differentiableAt_const _
    -- Apply CLM chain rule to `y â†¦ c y (u y)`.
    have h' := deriv_clm_apply (ð•œ := â„) (c := c) (u := u) hc hu
    -- Since `u` is constant, its derivative vanishes and we obtain the commutation.
    have h'' :
        deriv (fun y => c y (u y)) q.2 =
          deriv c q.2 (u q.2) := by
      simpa [u, deriv_const, add_comm] using h'
    -- Rewrite in terms of the original functions.
    simpa [c, u] using h''.symm
  rw [h_comm]
  congr; ext y
  change fderiv â„ f (q.1, y) v = _
  have h_f_diff : DifferentiableAt â„ f (q.1, y) := h.differentiable (by norm_num) _
  rw [deriv_slice_snd_eq_fderiv h_f_diff]

/-- Laplacian of a constant function is zero. -/
lemma laplacian_const (c : â„) (x : E) :
    laplacian (fun _ : E => c) x = 0 := by
  classical
  simp [laplacian_def, hessian_const, Finset.sum_const_zero]

/-- Laplacian of an affineâ€‘linear function is zero. -/
lemma laplacian_linear_add_const (L : E â†’L[â„] â„) (c : â„) (x : E) :
    laplacian (fun y : E => L y + c) x = 0 := by
  classical
  simp [laplacian_def, hessian_linear_add_const]  -- all terms in the sum are zero

/-- If `f` has vanishing Hessian at `x`, then its Laplacian at `x` is zero. -/
lemma laplacian_of_hessian_eq_zero {f : E â†’ â„} {x : E}
    (h : hessian f x = 0) :
    laplacian f x = 0 := by
  classical
  simp [laplacian_def, h]

/-!
Further coordinate descriptions (e.g., on `â„ Ã— â„` as a sum of second partial derivatives)
will be added in future work once the corresponding Hessian / second derivative API in
`mathlib` has been developed to the required level of generality.
-/

/-! ### Specialization to Euclidean space `â„^2` -/

section Euclidean2

open Fin Module

/-- The standard 2â€‘dimensional Euclidean real inner product space. -/
abbrev E2 : Type := EuclideanSpace â„ (Fin 2)

/-- The real dimension of `E2` is `2`. -/
lemma finrank_E2 : Module.finrank â„ E2 = 2 := by
  -- `EuclideanSpace â„ (Fin n)` always has finrank `n`.
  simp [E2]

variable (f : E2 â†’ â„) (x : E2)

/-- Second directional derivative of `f` at `x` along the `i`â€‘th vector of the
standard orthonormal basis, expressed via the Hessian. -/
noncomputable def secondDerivOnStdONB (i : Fin (finrank â„ E2)) : â„ :=
  let b := stdOrthonormalBasis â„ E2
  hessian f x (b i) (b i)

/--
On `â„^2` (real Euclidean space), the Laplacian of a scalar field `f` at `x` is the sum
of second directional derivatives along the standard orthonormal basis vectors.
-/
lemma laplacian_eq_sum_secondDeriv_E2 :
    laplacian f x = âˆ‘ i, secondDerivOnStdONB f x i := by
  classical
  -- This is just a restatement of the Laplacian formula in this concrete case.
  simpa [secondDerivOnStdONB] using
    (laplacian_def (E := E2) (f := f) (x := x))

end Euclidean2

end Laplacian

section Isometry

variable
  {E F : Type*}
  [NormedAddCommGroup E] [InnerProductSpace â„ E] [FiniteDimensional â„ E]
  [NormedAddCommGroup F] [InnerProductSpace â„ F] [FiniteDimensional â„ F]

open scoped BigOperators

/-! ### Hessian chain rule and Laplacian invariance under isometries -/

section ChainRule

open ContinuousLinearMap

variable {E F G : Type*}
  [NormedAddCommGroup E] [NormedSpace â„ E]
  [NormedAddCommGroup F] [NormedSpace â„ F]
  [NormedAddCommGroup G] [NormedSpace â„ G]

/-- FrÃ©chet derivative of a composition with a continuous linear map.

If `g : F â†’ G` is differentiable at `L x`, then
\[
  fderiv (g âˆ˜ L)(x) = (fderiv g (L x)).comp L.
\]
-/
lemma fderiv_compCLM
    (g : F â†’ G) (L : E â†’L[â„] F) (x : E)
    (hg : DifferentiableAt â„ g (L x)) :
    fderiv â„ (fun y : E => g (L y)) x
      = (fderiv â„ g (L x)).comp L := by
  classical
  -- `L` has derivative `L` at every point.
  have hL : HasFDerivAt (fun y : E => L y) L x := L.hasFDerivAt
  -- `g` has derivative `fderiv g (L x)` at `L x` by hypothesis.
  have hg' : HasFDerivAt g (fderiv â„ g (L x)) (L x) := hg.hasFDerivAt
  -- Chain rule for the composition `g âˆ˜ L`.
  have hcomp : HasFDerivAt (fun y : E => g (L y))
      ((fderiv â„ g (L x)).comp L) x :=
    hg'.comp x hL
  -- Turn the `HasFDerivAt` into an equality for `fderiv`.
  exact hcomp.fderiv

variable {E F : Type*}
  [NormedAddCommGroup E] [NormedSpace â„ E]
  [NormedAddCommGroup F] [NormedSpace â„ F]

/-- Directional chain rule for the derivative when postâ€‘composing by a fixed continuous
linear map `T : E â†’L[â„] F`.

If `h : E â†’ F â†’L[â„] â„` and `hh : HasFDerivAt h (fderiv â„ h x) x`, then for each `v : E` we have
\[
  fderiv (Î» y, (h y).comp T)(x)\,v = (fderiv h x\,v).comp T.
\]
We use this only inside the Hessian chain rule. -/
lemma fderiv_comp_rightCLM
    (h : E â†’ F â†’L[â„] â„) (T : E â†’L[â„] F) (x v : E)
    (hh : HasFDerivAt h (fderiv â„ h x) x) :
    fderiv â„ (fun y : E => (h y).comp T) x v
      = (fderiv â„ h x v).comp T := by
  classical
  -- Underlying linear map: postâ€‘composition by `T`.
  let Ï†_lin : (F â†’L[â„] â„) â†’â‚—[â„] (E â†’L[â„] â„) :=
    { toFun := fun A => A.comp T
      , map_add' := by
          intro A B; ext x'
          simp
      , map_smul' := by
          intro c A; ext x'
          simp [smul_comp] }
  -- Uniform bound: â€–A.comp Tâ€– â‰¤ â€–Tâ€– * â€–Aâ€–.
  have hÏ†_bd : âˆ€ A : F â†’L[â„] â„, â€–Ï†_lin Aâ€– â‰¤ â€–Tâ€– * â€–Aâ€– := by
    intro A
    have h := opNorm_comp_le (h := A) (f := T)
    simpa [Ï†_lin, mul_comm] using h
  -- Upgrade to a continuous linear map.
  let Ï† : (F â†’L[â„] â„) â†’L[â„] (E â†’L[â„] â„) :=
    LinearMap.mkContinuous Ï†_lin â€–Tâ€– (by
      intro A
      simpa using hÏ†_bd A)
  -- Now `y â†¦ (h y).comp T` is `Ï† âˆ˜ h`. Apply the FrÃ©chet chain rule.
  have hÏ† : HasFDerivAt (fun A : F â†’L[â„] â„ => Ï† A) Ï† (h x) :=
    Ï†.hasFDerivAt
  have hcomp : HasFDerivAt (fun y : E => Ï† (h y)) (Ï†.comp (fderiv â„ h x)) x :=
    hÏ†.comp x hh
  -- Turn this into an equality for `fderiv`.
  have hcomp_fd : fderiv â„ (fun y : E => Ï† (h y)) x
        = (Ï†.comp (fderiv â„ h x)) :=
    hcomp.fderiv
  -- Evaluate both sides at `v`.
  have hcomp_apply :
      fderiv â„ (fun y : E => Ï† (h y)) x v
        = (Ï†.comp (fderiv â„ h x)) v := by
    -- apply the equality of linear maps to `v`
    simpa using congrArg (fun L => L v) hcomp_fd
  -- This is exactly the desired directional equality.
  simpa [Function.comp, Ï†] using hcomp_apply

/-- `fderiv` of a composition with a continuous linear map.

If `g : F â†’ â„` is differentiable at `L x`, then
\[
  fderiv (g âˆ˜ L)(x) = (fderiv g (L x)).comp L.
\]
-/
lemma fderiv_compCLM'
    (g : F â†’ â„) (L : E â†’L[â„] F) (x : E)
    (hg : DifferentiableAt â„ g (L x)) :
    fderiv â„ (fun y : E => g (L y)) x
      = (fderiv â„ g (L x)).comp L := by
  classical
  -- `L` has derivative `L` at every point.
  have hL : HasFDerivAt (fun y : E => L y) L x := L.hasFDerivAt
  -- `g` has derivative `fderiv g (L x)` at `L x` by hypothesis.
  have hg' : HasFDerivAt g (fderiv â„ g (L x)) (L x) :=
    hg.hasFDerivAt
  -- Chain rule for the composition `g âˆ˜ L`.
  have hcomp : HasFDerivAt (fun y : E => g (L y))
      ((fderiv â„ g (L x)).comp L) x :=
    hg'.comp x hL
  -- Turn the `HasFDerivAt` into an equality for `fderiv`.
  exact hcomp.fderiv

lemma hessian_comp_linear
    (g : F â†’ â„) (L : E â†’L[â„] F) (x v w : E)
    (hg1 : âˆ€ y : E, DifferentiableAt â„ g (L y))
    (hg2 : DifferentiableAt â„ (fun z : F => fderiv â„ g z) (L x)) :
  hessian (fun y : E => g (L y)) x v w
    = hessian g (L x) (L v) (L w) := by
  classical
  -- Let f := g âˆ˜ L.
  let f : E â†’ â„ := fun y => g (L y)

  -- Hessians as second derivatives
  have hf :
      hessian f x v w
        = (fderiv â„ (fun y : E => fderiv â„ f y) x v) w := rfl
  have hg_hess :
      hessian g (L x) (L v) (L w)
        = (fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)) (L w) := rfl

  -- 1st derivative of f via chain rule
  have h_fderiv :
      âˆ€ y, fderiv â„ f y = (fderiv â„ g (L y)).comp L := by
    intro y
    have hgd : DifferentiableAt â„ g (L y) := hg1 y
    simpa [f] using fderiv_compCLM (g := g) (L := L) (x := y) hgd

  -- define h(y) = fderiv g (L y)
  let h : E â†’ F â†’L[â„] â„ := fun y => fderiv â„ g (L y)

  have h_fd :
      âˆ€ y, fderiv â„ f y = (h y).comp L := by
    intro y; simpa [h] using h_fderiv y

  -- derivative of h at x
  have hh_deriv :
      fderiv â„ h x = (fderiv â„ (fun z : F => fderiv â„ g z) (L x)).comp L := by
    have hgd2 : DifferentiableAt â„ (fun z : F => fderiv â„ g z) (L x) := hg2
    simpa [h] using
      fderiv_compCLM (g := fun z : F => fderiv â„ g z) (L := L) (x := x) hgd2

  have hh : HasFDerivAt h (fderiv â„ h x) x := by
    -- h is definitionally (fun z => fderiv â„ g z) âˆ˜ L
    have h_eq : h = fun y => (fun z : F => fderiv â„ g z) (L y) := rfl
    rw [h_eq]
    -- Now we need to show fderiv matches what comp gives us
    have hcomp := hg2.hasFDerivAt.comp x L.hasFDerivAt
    convert hcomp using 2
  -- second derivative of f: derivative of y â†¦ fderiv f y
  have h_second :
      fderiv â„ (fun y : E => fderiv â„ f y) x v
        = (fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)).comp L := by
    -- rewrite fderiv f via h_fd
    have h_eq :
        fderiv â„ (fun y : E => fderiv â„ f y) x v
          = fderiv â„ (fun y : E => (h y).comp L) x v := by
      have : (fun y : E => fderiv â„ f y) = fun y : E => (h y).comp L := by
        funext y; simp [h_fd y]
      simp [this]
    have h_post :
        fderiv â„ (fun y : E => (h y).comp L) x v
          = (fderiv â„ h x v).comp L :=
      fderiv_comp_rightCLM h L x v hh
    -- compute fderiv h x v using hh_deriv
    have h_pre :
        fderiv â„ h x v
          = fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v) := by
      -- apply both sides of hh_deriv to v
      have := congrArg (fun (T : E â†’L[â„] F â†’L[â„] â„) => T v) hh_deriv
      -- RHS simplifies: ((fderiv ... (L x)).comp L) v = (fderiv ... (L x)) (L v)
      simpa using this
    calc
      fderiv â„ (fun y : E => fderiv â„ f y) x v
          = fderiv â„ (fun y : E => (h y).comp L) x v := h_eq
      _   = (fderiv â„ h x v).comp L := h_post
      _   = (fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)).comp L := by
              simp [h_pre]

  -- finally evaluate at w and compare Hessians
  calc
    hessian f x v w
        = (fderiv â„ (fun y : E => fderiv â„ f y) x v) w := hf
    _   = ((fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)).comp L) w := by
            simp [h_second]
    _   = (fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)) (L w) := rfl
    _   = hessian g (L x) (L v) (L w) := (hg_hess).symm

/-
/--
Chain rule for the Hessian under a continuous linear map `L : E â†’L[â„] F`.

This version is purely formal: it relates the second FrÃ©chet derivatives of `g âˆ˜ L`
and `g` via the chain rule for `fderiv`. Regularity assumptions (`ContDiffAt â„ 2 g`)
should be expressed in separate lemmas.
-/
lemma hessian_comp_linear'
    (g : F â†’ â„) (L : E â†’L[â„] F) (x v w : E) :
    hessian (fun y : E => g (L y)) x v w
      = hessian g (L x) (L v) (L w) := by
  classical
  -- Let `f := g âˆ˜ L`.
  let f : E â†’ â„ := fun y => g (L y)
  -- Unfold Hessians in terms of second FrÃ©chet derivatives.
  have hf :
      hessian f x v w
        = (fderiv â„ (fun y : E => fderiv â„ f y) x v) w := rfl
  have hg_hess :
      hessian g (L x) (L v) (L w)
        = (fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)) (L w) := rfl
  -- Rewrite the first derivative of `f` using `fderiv_compCLM'`.
  have h_fderiv :
      âˆ€ y, fderiv â„ f y = (fderiv â„ g (L y)).comp L := by
    intro y
    -- you already have `fderiv_compCLM'` for `g : F â†’ â„` and `L : E â†’L[â„] F`
    -- once you assume differentiability of `g` at `L y`.
    -- For the formal identity, we treat this as the intended form.
    -- TODO: replace by a genuine chain-rule lemma `fderiv_compCLM'` when available.
    admit
  -- Define `h : E â†’ F â†’L[â„] â„` and express `fderiv f` via `h`.
  let h : E â†’ F â†’L[â„] â„ := fun y => fderiv â„ g (L y)
  have h_fd :
      âˆ€ y, fderiv â„ f y = (h y).comp L := by
    intro y
    simpa [f, h] using h_fderiv y
  -- Second derivative of `f` at `x` in direction `v`:
  -- derivative of `y â†¦ fderiv f y` at `x` applied to `v`.
  have h_second :
      fderiv â„ (fun y : E => fderiv â„ f y) x v
        = (fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)).comp L := by
    -- Rewrite the outer `fderiv` using `h_fd` and your directional postâ€‘composition lemma.
    admit
  -- Evaluate at `w` and use the two `hf` / `hg_hess` rewrites.
  calc
    hessian f x v w
        = (fderiv â„ (fun y : E => fderiv â„ f y) x v) w := hf
    _   = ((fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)).comp L) w := by
            simpa [h_second]
    _   = (fderiv â„ (fun z : F => fderiv â„ g z) (L x) (L v)) (L w) := rfl
    _   = hessian g (L x) (L v) (L w) := (hg_hess).symm
    -/

/-- Specialization of the Hessian chain rule to a *linear isometry* (as a continuous linear map). -/
lemma hessian_comp_linearIsometry
    (g : F â†’ â„) (e : E â‰ƒâ‚—áµ¢[â„] F) (x v w : E)
    (hg1 : âˆ€ y : E, DifferentiableAt â„ g (e y))
    (hg2 : DifferentiableAt â„ (fun z : F => fderiv â„ g z) (e x)) :
    hessian (fun y : E => g (e y)) x v w
      = hessian g (e x) (e v) (e w) := by
  -- Just instantiate `hessian_comp_linear` with `L := (e : E â†’L[â„] F)`.
  simpa using
    (hessian_comp_linear (g := g) (L := (e : E â†’L[â„] F))
      (x := x) (v := v) (w := w)
      (hg1 := hg1) (hg2 := hg2))

/-- Diagonal version of the Hessian chain rule under a linear isometry. -/
lemma hessian_comp_linearIsometry_diag
    (g : F â†’ â„) (e : E â‰ƒâ‚—áµ¢[â„] F) (x v : E)
    (hg1 : âˆ€ y : E, DifferentiableAt â„ g (e y))
    (hg2 : DifferentiableAt â„ (fun z : F => fderiv â„ g z) (e x)) :
    hessian (fun y : E => g (e y)) x v v
      = hessian g (e x) (e v) (e v) :=
  hessian_comp_linearIsometry g e x v v hg1 hg2

end ChainRule

/-! ### Laplacian invariance under linear isometries -/

section LaplacianIsometry

open scoped BigOperators InnerProductSpace

variable
  {E F : Type*}
  [NormedAddCommGroup E] [InnerProductSpace â„ E] [FiniteDimensional â„ E]
  [NormedAddCommGroup F] [InnerProductSpace â„ F] [FiniteDimensional â„ F]

/--
Laplacian invariance under a linear isometry: if `e : E â‰ƒâ‚—áµ¢[â„] F` is a linear isometry and
`f : F â†’ â„`, then
\[
  \Delta (f âˆ˜ e)(x) = \Delta f(e x).
\]
-/
/-
If `e : E â‰ƒâ‚—áµ¢[â„] F` is a linear isometry and `f : F â†’ â„`, then the Laplacian of the pullback
`x â†¦ f (e x)` at `x` equals the Laplacian of `f` at `e x`.

Mathematically: `Î”(f âˆ˜ e)(x) = Î”f(e x)`.
-/
lemma laplacian_comp_linearIsometryEquiv
    (e : E â‰ƒâ‚—áµ¢[â„] F) (f : F â†’ â„) (x : E)
    (hf1 : âˆ€ y : E, DifferentiableAt â„ f (e y))
    (hf2 : DifferentiableAt â„ (fun z : F => fderiv â„ f z) (e x)) :
    laplacian (fun y : E => f (e y)) x = laplacian f (e x) := by
  classical
  -- Choose an orthonormal basis on `E`.
  let bE := stdOrthonormalBasis â„ E
  -- Its image under `e` is an orthonormal basis on `F`.
  let bF : OrthonormalBasis _ â„ F := bE.map e
  -- Express both Laplacians in terms of these bases.
  have hLap_comp :
      laplacian (fun y : E => f (e y)) x
        = âˆ‘ i, hessian (fun y : E => f (e y)) x (bE i) (bE i) :=
    laplacian_eq_sum_orthonormal (b := bE) _ _
  have hLap_f :
      laplacian f (e x)
        = âˆ‘ i, hessian f (e x) (bF i) (bF i) := by
    simpa using
      (laplacian_eq_sum_orthonormal (b := bF) (f := f) (x := e x))
  -- Use the Hessian chain rule along `e` on each diagonal entry.
  have h_diag :
      âˆ€ i, hessian (fun y : E => f (e y)) x (bE i) (bE i)
            = hessian f (e x) (bF i) (bF i) := by
    intro i
    -- `bF i = e (bE i)` by definition of `map`.
    have hbFi : bF i = e (bE i) := by
      simp [bF]
    -- Chain rule on the diagonal, with differentiability hypotheses `hf1`, `hf2`.
    -- Note: `hf1` and `hf2` match exactly the parameters of `hessian_comp_linearIsometry_diag`.
    rw [hbFi, hessian_comp_linearIsometry_diag (g := f) e x (bE i) hf1 hf2]
  -- Summing over `i` gives the result.
  calc
    laplacian (fun y : E => f (e y)) x
        = âˆ‘ i, hessian (fun y : E => f (e y)) x (bE i) (bE i) := hLap_comp
    _ = âˆ‘ i, hessian f (e x) (bF i) (bF i) := by
          refine Finset.sum_congr rfl ?_
          intro i _
          simpa using h_diag i
    _ = laplacian f (e x) := hLap_f.symm

end LaplacianIsometry




end Isometry

/-! ## Harmonic functions -/

section Harmonic

variable {E : Type*} [NormedAddCommGroup E] [InnerProductSpace â„ E] [FiniteDimensional â„ E]
open scoped Topology
open InnerProductSpace Filter

/-- A scalar field `f : E â†’ â„` is harmonic on a set `s` if it is twice continuously
FrÃ©chetâ€‘differentiable at every point of `s` and its Laplacian vanishes there.
This is an alias for mathlib's `HarmonicOnNhd`. -/
abbrev IsHarmonicOn (f : E â†’ â„) (s : Set E) : Prop :=
  HarmonicOnNhd f s

/-- Being harmonic is a local property that is monotone with respect to the set. -/
lemma IsHarmonicOn.mono {f : E â†’ â„} {s t : Set E}
    (h : IsHarmonicOn f t) (hst : s âŠ† t) :
    IsHarmonicOn f s :=
  HarmonicOnNhd.mono h hst

/-- Extract pointwise Laplacian vanishing from harmonicity. -/
lemma IsHarmonicOn.laplacian_eq_zero {f : E â†’ â„} {s : Set E} {x : E}
    (h : IsHarmonicOn f s) (hx : x âˆˆ s) :
    laplacian f x = 0 := by
  have hHarm := h x hx
  exact Filter.EventuallyEq.eq_of_nhds hHarm.2

/-- A constant function is harmonic on any set. -/
lemma IsHarmonicOn_const (c : â„) (s : Set E) :
    IsHarmonicOn (fun _ => c) s := by
  intro x _
  refine âŸ¨contDiffAt_const, ?_âŸ©
  -- Laplacian of constant is 0
  apply Filter.eventually_of_mem (Filter.univ_mem)
  intro y
  simp [laplacian_const]

/-- An affine function is harmonic on any set. -/
lemma IsHarmonicOn_linear_add_const (L : E â†’L[â„] â„) (c : â„) (s : Set E) :
    IsHarmonicOn (fun x => L x + c) s := by
  intro x _
  refine âŸ¨?_, ?_âŸ©
  Â· apply ContDiffAt.add
    Â· apply L.contDiff.contDiffAt
    Â· apply contDiffAt_const
  Â· apply Filter.eventually_of_mem (Filter.univ_mem)
    intro y
    simp [laplacian_linear_add_const]

end Harmonic

section GradDiv
open scoped Gradient RealInnerProductSpace

open InnerProductSpace
open scoped BigOperators InnerProductSpace

variable {E : Type*} [NormedAddCommGroup E] [InnerProductSpace â„ E] [FiniteDimensional â„ E]

/-- Just a synonym for the mathlib gradient in the real Hilbert setting. -/
abbrev grad (f : E â†’ â„) (x : E) : E := âˆ‡ f x

/-- Divergence of a vector field, defined as the trace of its FrÃ©chet derivative. -/
def divergence (F : E â†’ E) (x : E) : â„ :=
  let b := stdOrthonormalBasis â„ E
  âˆ‘ i, âŸªfderiv â„ F x (b i), b iâŸ«

/-- Characterization of the gradient via the inner product. -/
lemma inner_grad (f : E â†’ â„) (x v : E) :
    âŸªgrad f x, vâŸ« = fderiv â„ f x v := by
  -- `grad` is the real gradient, defined via `toDual.symm (fderiv f x)`.
  unfold grad gradient
  -- Riesz representation: `âŸª(toDual â„ E).symm â„“, vâŸ« = â„“ v`.
  simp

/-- The Laplacian is the divergence of the gradient.

We need a `CÂ²` hypothesis to justify the chain rule for the FrÃ©chet derivative:
both sides are defined unconditionally, but equality is only guaranteed when
the relevant derivatives exist. -/
lemma laplacian_eq_divergence_grad
    (f : E â†’ â„) (x : E) (hf : ContDiffAt â„ 2 f x) :
    laplacian f x = divergence (fun y => grad f y) x := by
  classical
  -- Work with the standard orthonormal basis.
  let b := stdOrthonormalBasis â„ E

  -- First, rewrite both sides as sums over `b`.
  have h_lap :
      laplacian f x = âˆ‘ i, hessian f x (b i) (b i) :=
    laplacian_eq_sum_orthonormal (b := b) f x

  have h_div :
      divergence (fun y => grad f y) x
        = âˆ‘ i, âŸªfderiv â„ (fun y => grad f y) x (b i), b iâŸ« := by
    simp [divergence, b]

  -- We reduce to showing equality termwise in the sum.
  have h_diag :
      âˆ€ i, hessian f x (b i) (b i)
            = âŸªfderiv â„ (fun y => grad f y) x (b i), b iâŸ« := by
    intro i
    -- Define `g := grad f` and the scalar function `h(y) = âŸªg y, b iâŸ«`.
    let g : E â†’ E := fun y => grad f y
    let h : E â†’ â„ := fun y => âŸªg y, b iâŸ«

    -- (1) `h` is `CÂ²` at `x` as a composition of smooth maps, since `f` is `CÂ²`.
    have hg : ContDiffAt â„ 1 g x := by
      -- `f` is `CÂ²`, so `y â†¦ fderiv â„ f y` is `CÂ¹` at `x`.
      have hf' : ContDiffAt â„ 1 (fderiv â„ f) x :=
        (ContDiffAt.fderiv_right (xâ‚€ := x) (f := f) (n := (2 : â„•âˆž))
          (m := (1 : â„•âˆž)) hf (by norm_cast))  -- 1 + 1 â‰¤ 2
      -- The inverse Riesz isometry `toDual.symm` is `C^âˆž`.
      have h_outer :
          ContDiffAt â„ 1 ((InnerProductSpace.toDual â„ E).symm) (fderiv â„ f x) :=
        (InnerProductSpace.toDual â„ E).symm.contDiff.contDiffAt
      -- Compose `toDual.symm` with `fderiv â„ f`.
      have h_comp :
          ContDiffAt â„ 1
            (fun y => (InnerProductSpace.toDual â„ E).symm (fderiv â„ f y)) x :=
        h_outer.comp x hf'
      -- This composite is exactly `g`.
      simpa [g, grad, gradient] using h_comp

    have hh : ContDiffAt â„ 1 h x := by
      -- `h` is the inner product with a fixed vector applied to `g y`.
      -- First, `z â†¦ âŸªz, b iâŸ«` is `C^âˆž`, hence `CÂ¹`.
      have hCLM_top : ContDiffAt â„ âŠ¤ (fun z : E => âŸªz, b iâŸ«) (g x) := by
        -- Take `f := id`, `gâ‚€ := fun _ => b i` and use `ContDiffAt.inner`.
        have hf : ContDiffAt â„ âŠ¤ (fun z : E => z) (g x) := contDiffAt_id
        have hgâ‚€ : ContDiffAt â„ âŠ¤ (fun _ : E => b i) (g x) := contDiffAt_const
        simpa using (hf.inner (ð•œ := â„) hgâ‚€)
      -- Downgrade from `C^âˆž` to `CÂ¹`.
      have hCLM : ContDiffAt â„ 1 (fun z : E => âŸªz, b iâŸ«) (g x) :=
        hCLM_top.of_le (by exact le_top)
      -- Now compose with `g`, which is `CÂ¹` at `x`.
      exact hCLM.comp x hg

    -- (2) Derivative of `h` along `b i` via the Hessian:
    -- Using the definition of `hessian`, we have
    -- `fderiv h x (b i) = hessian f x (b i) (b i)`.
    have hâ‚ :
        fderiv â„ h x (b i) = hessian f x (b i) (b i) := by
      -- Unfold `h` and `g`: `h y = âŸªgrad f y, b iâŸ« = âŸª(toDual.symm) (fderiv â„ f y), b iâŸ«`.
      -- By the Riesz representation, this equals `(fderiv â„ f y) ((toDual â„ E) (b i))`.
      -- But `toDual (b i)` is the functional `âŸ¨Â·, b iâŸ©`, so we can also work directly
      -- with the inner product derivative formula.
      -- The key identity is: for any linear functional `L : E â†’L[â„] â„`,
      -- `âŸª(toDual.symm) L, vâŸ« = L v`.
      have toDual_apply : âˆ€ (L : E â†’L[â„] â„) (v : E),
          âŸª(InnerProductSpace.toDual â„ E).symm L, vâŸ« = L v :=
        fun L v => by simp [InnerProductSpace.toDual_symm_apply]
      -- Now apply the chain rule to `g = (toDual.symm) âˆ˜ (fderiv â„ f)`.
      have hg_eq : g = (InnerProductSpace.toDual â„ E).symm âˆ˜ (fderiv â„ f) := rfl
      -- The derivative of `g` at `x` is the composition of derivatives:
      -- `fderiv â„ g x = (toDual.symm) âˆ˜L (fderiv â„ (fderiv â„ f) x)`.
      have hg_diff : DifferentiableAt â„ (fderiv â„ f) x := by
        exact (ContDiffAt.fderiv_right (xâ‚€ := x) (f := f) (n := (2 : â„•âˆž))
          (m := (1 : â„•âˆž)) hf (by norm_cast)).differentiableAt (by simp)
      have hg_fderiv :
          fderiv â„ g x
            = (InnerProductSpace.toDual â„ E).symm.toContinuousLinearEquiv.toContinuousLinearMap.comp
              (fderiv â„ (fderiv â„ f) x) := by
        rw [hg_eq]
        exact (InnerProductSpace.toDual â„ E).symm.toContinuousLinearEquiv.comp_fderiv
      -- Now compute `fderiv â„ h x (b i)`.
      -- `h y = âŸªg y, b iâŸ«`, so by the formula we already proved (hâ‚‚),
      -- we also have `fderiv â„ h x (b i) = âŸªfderiv â„ g x (b i), b iâŸ«`.
      -- Substitute the expression for `fderiv â„ g x`:
      calc fderiv â„ h x (b i)
          = âŸªfderiv â„ g x (b i), b iâŸ« := by
              -- This is what `hâ‚‚` will show (we prove it below).
              have hg_diff' : DifferentiableAt â„ g x := hg.differentiableAt (by simp)
              have hconst : DifferentiableAt â„ (fun _ : E => b i) x :=
                differentiableAt_const _
              simpa [h, fderiv_const] using
                fderiv_inner_apply â„ hg_diff' hconst (b i)
        _ = âŸª(InnerProductSpace.toDual â„ E).symm
              (fderiv â„ (fderiv â„ f) x (b i)), b iâŸ« := by
              rw [hg_fderiv]
              rfl
        _ = (fderiv â„ (fderiv â„ f) x (b i)) (b i) :=
              toDual_apply _ _
        _ = hessian f x (b i) (b i) := by
              simp [hessian]

    -- (3) Derivative of `h` along `b i` via `fderiv g` and the inner product.
    have hâ‚‚ :
        fderiv â„ h x (b i) = âŸªfderiv â„ g x (b i), b iâŸ« := by
      -- `h y = âŸªg y, b iâŸ«`. Use the general derivative formula for the inner product.
      have hg_diff : DifferentiableAt â„ g x := by
        -- from `ContDiffAt â„ 1 g x` we get differentiability since `1 â‰¤ 1`
        exact hg.differentiableAt (by simp)
      have hconst : DifferentiableAt â„ (fun _ : E => b i) x :=
        differentiableAt_const _
      have h1 :=
        fderiv_inner_apply â„
          hg_diff hconst (b i)
      -- `h1` says:
      -- `fderiv â„ (fun t => âŸªg t, b iâŸ«) x (b i)
      --    = âŸªg x, 0âŸ« + âŸªfderiv â„ g x (b i), b iâŸ«`.
      -- Simplify RHS and rewrite LHS as `fderiv â„ h x (b i)`.
      simpa [h, fderiv_const] using h1

    -- Combine the two expressions for `fderiv h x (b i)`.
    aesop

  -- Sum the diagonal identities.
  calc
    laplacian f x
        = âˆ‘ i, hessian f x (b i) (b i) := h_lap
    _   = âˆ‘ i, âŸªfderiv â„ (fun y => grad f y) x (b i), b iâŸ« := by
            refine Finset.sum_congr rfl ?_
            intro i _
            exact h_diag i
    _   = divergence (fun y => grad f y) x := h_div.symm

end GradDiv

section ComplexHarmonic

open Complex
open InnerProductSpace

/-- At a point: the real part of an analytic function is harmonic
(i.e. its Laplacian vanishes). -/
lemma laplacian_re_of_analyticAt
    {f : â„‚ â†’ â„‚} {z : â„‚} (hf : AnalyticAt â„‚ f z) :
    laplacian (fun w : â„‚ => (f w).re) z = 0 := by
  classical
  -- Mathlib: real part of an analytic map is harmonic on `â„‚`.
  have hHarm :
      InnerProductSpace.HarmonicAt
        (E := â„‚) (F := â„) (fun w : â„‚ => (f w).re) z :=
    (AnalyticAt.harmonicAt_re (f := f) (x := z) hf)
  -- `HarmonicAt` says: `ContDiffAt â„ 2` and Laplacian vanishes in a neighborhood.
  -- Evaluate the eventual equality at `z`.
  have hLap :
      (InnerProductSpace.laplacian (E := â„‚) (F := â„)
        (fun w : â„‚ => (f w).re)) z = 0 :=
    Filter.EventuallyEq.eq_of_nhds hHarm.2
  -- Our `laplacian` is by definition the scalar Laplacian on `â„‚`.
  simpa [laplacian] using hLap

/-- At a point: the imaginary part of an analytic function is harmonic. -/
lemma laplacian_im_of_analyticAt
    {f : â„‚ â†’ â„‚} {z : â„‚} (hf : AnalyticAt â„‚ f z) :
    laplacian (fun w : â„‚ => (f w).im) z = 0 := by
  classical
  have hHarm :
      InnerProductSpace.HarmonicAt
        (E := â„‚) (F := â„) (fun w : â„‚ => (f w).im) z :=
    (AnalyticAt.harmonicAt_im (f := f) (x := z) hf)
  have hLap :
      (InnerProductSpace.laplacian (E := â„‚) (F := â„)
        (fun w : â„‚ => (f w).im)) z = 0 :=
    Filter.EventuallyEq.eq_of_nhds hHarm.2
  simpa [laplacian] using hLap

/-- On a set: the real part of an analytic function is harmonic. -/
lemma isHarmonicOn_re_of_analyticOn
    {f : â„‚ â†’ â„‚} {s : Set â„‚} (hf : AnalyticOnNhd â„‚ f s) :
    IsHarmonicOn (fun z => (f z).re) s := by
  intro z hz
  exact AnalyticAt.harmonicAt_re (hf z hz)

/-- On a set: the imaginary part of an analytic function is harmonic. -/
lemma isHarmonicOn_im_of_analyticOn
    {f : â„‚ â†’ â„‚} {s : Set â„‚} (hf : AnalyticOnNhd â„‚ f s) :
    IsHarmonicOn (fun z => (f z).im) s := by
  intro z hz
  exact AnalyticAt.harmonicAt_im (hf z hz)

end ComplexHarmonic
